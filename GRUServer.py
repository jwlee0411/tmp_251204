import os

# [ì¤‘ìš”] 1. TensorFlow ì¶©ëŒ ë°©ì§€: CPUë§Œ ì‚¬ìš©í•˜ë„ë¡ ê°•ì œ ì„¤ì • (GPU ë©”ëª¨ë¦¬ ì˜¤ë¥˜ ë°©ì§€)
# ì„œë²„ê°€ í„°ì§€ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ ê°€ì¥ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"  # ë¶ˆí•„ìš”í•œ ë¡œê·¸ ìˆ¨ê¹€

import uvicorn
import numpy as np
import pandas as pd
import ccxt
import time
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from tensorflow.keras.models import load_model
from sklearn.preprocessing import StandardScaler

# ===== 1. ì„¤ì • ë° ëª¨ë¸ ë¡œë“œ =====

app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],    
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

MODEL_PATH = "best_model_GRU_tuned_v14.keras"
WINDOW_SIZE = 48 
PRICE_FEATURES = ['Open', 'High', 'Low', 'Close', 'Volume', 'MA5', 'MA20']
INDICATOR_FEATURES = ['RSI', 'MACD', 'Signal_Line', 'Log_Return', 'ATR', '%K', '%D']
ALL_FEATURES = PRICE_FEATURES + INDICATOR_FEATURES 

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ì„ ì–¸
model = None

# [ì¤‘ìš”] 2. ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë“œ (Startup Event í™œìš©)
@app.on_event("startup")
async def startup_event():
    global model
    print("â³ Loading Model...")
    start_time = time.time()
    try:
        # ëª¨ë¸ ë¡œë“œ
        model = load_model(MODEL_PATH)
        print(f"âœ… GRU Model Loaded Successfully! ({time.time() - start_time:.2f}s)")
        
        # [í…ŒìŠ¤íŠ¸] ë”ë¯¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡ í•œ ë²ˆ ì‹¤í–‰ (Warm-up)
        # ì²˜ìŒ ìš”ì²­ ì‹œ ëŠë¦° í˜„ìƒì„ ë°©ì§€
        dummy_input = np.zeros((1, WINDOW_SIZE, len(ALL_FEATURES)))
        model.predict(dummy_input, verbose=0)
        print("âœ… Model Warm-up Complete!")
        
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì„œë²„ë¥¼ ì¢…ë£Œí•˜ì§€ ì•Šê³  None ì²˜ë¦¬ (ë””ë²„ê¹…ìš©)
        model = None

# ì‘ë‹µ DTO ì •ì˜
class ChartDataDto(BaseModel):
    date: str       
    value: float    

# ===== 2. ë°ì´í„° ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° =====

def get_binance_data(limit=1500):
    """CCXTë¥¼ ì´ìš©í•´ ë°”ì´ë‚¸ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ ì¶”ê°€)"""
    exchange = ccxt.binance({
        'timeout': 10000, # 10ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì •
        'enableRateLimit': True,
    })
    try:
        # fetch_ohlcvëŠ” ë„¤íŠ¸ì›Œí¬ ìƒí™©ì— ë”°ë¼ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŒ
        ohlcv = exchange.fetch_ohlcv('BTC/USDT', timeframe='1h', limit=limit)
        if not ohlcv:
            raise ValueError("Empty data returned")
            
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Date'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('Date', inplace=True)
        return df.drop(columns=['timestamp'])
    except Exception as e:
        print(f"âŒ Binance Fetch Error: {e}")
        raise HTTPException(status_code=500, detail=f"Binance data fetch failed: {str(e)}")

def calculate_technical_indicators(df):
    """í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•œ ë³´ì¡°ì§€í‘œ ê³„ì‚° ë¡œì§"""
    df = df.copy()
    
    # RSI
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / (loss + 1e-9)
    df['RSI'] = 100 - (100 / (1 + rs))
    
    # MACD
    ema_12 = df['Close'].ewm(span=12, adjust=False).mean()
    ema_26 = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = ema_12 - ema_26
    df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()
    
    # Moving Averages & Log Return
    df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1))
    df['MA5'] = df['Close'].rolling(window=5).mean()
    df['MA20'] = df['Close'].rolling(window=20).mean()
    df['ATR'] = (df['High'] - df['Low']).rolling(window=14).mean()
    
    # Stochastic
    low_min = df['Low'].rolling(14).min()
    high_max = df['High'].rolling(14).max()
    df['%K'] = 100 * (df['Close'] - low_min) / (high_max - low_min + 1e-9)
    df['%D'] = df['%K'].rolling(3).mean()
    
    return df

def prepare_inference_data():
    # 1. ë°ì´í„° ìˆ˜ì§‘
    df = get_binance_data(limit=1000) # limitë¥¼ 1000ìœ¼ë¡œ ì¤„ì—¬ì„œ ì†ë„ í–¥ìƒ
    
    # 2. ë³´ì¡°ì§€í‘œ ê³„ì‚°
    df = calculate_technical_indicators(df)
    
    # 3. Stationarizing
    for col in PRICE_FEATURES:
        if col in df.columns:
            df[col] = df[col].pct_change(1)
            
    for col in INDICATOR_FEATURES:
        if col in df.columns:
            df[col] = df[col].diff(1)
            
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.dropna(inplace=True)
    
    # 4. Feature Selection
    final_df = df[ALL_FEATURES]
    
    # 5. Scaling [ì£¼ì˜: ìˆ˜ì • í•„ìš”]
    # ì¢…ìš°ë‹˜, ì›ë˜ëŠ” í•™ìŠµ ë•Œ ì €ì¥í•œ scaler.pklì„ ë¶ˆëŸ¬ì™€ì„œ scaler.transform(final_df) í•´ì•¼ í•©ë‹ˆë‹¤.
    # í˜„ì¬ëŠ” ì„ì‹œë°©í¸ìœ¼ë¡œ ìƒˆ Scalerë¥¼ ì“°ì§€ë§Œ, ì •í™•ë„ê°€ ë§¤ìš° ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    scaler = StandardScaler() 
    scaled_values = scaler.fit_transform(final_df) 
    
    # 6. Sequence Generation
    x_input = []
    dates = []
    
    # ìµœê·¼ 200ê°œë§Œ ì˜ˆì¸¡ (ì†ë„ ìµœì í™”)
    prediction_limit = 200
    if len(scaled_values) > prediction_limit + WINDOW_SIZE:
        start_idx = len(scaled_values) - prediction_limit - WINDOW_SIZE
    else:
        start_idx = 0

    for i in range(start_idx, len(scaled_values) - WINDOW_SIZE):
        seq = scaled_values[i : i + WINDOW_SIZE]
        x_input.append(seq)
        target_date = final_df.index[i + WINDOW_SIZE - 1]
        dates.append(target_date)
        
    return np.array(x_input), dates

# ===== 3. API ì—”ë“œí¬ì¸íŠ¸ =====

@app.get("/api/predict/chart")
def get_prediction_chart():
    if model is None:
        raise HTTPException(status_code=503, detail="Model is currently loading or failed to load.")
        
    try:
        x_input, dates = prepare_inference_data()
        
        # ëª¨ë¸ ì˜ˆì¸¡ (Verbose=0ìœ¼ë¡œ ë¡œê·¸ ìˆ¨ê¹€)
        predictions = model.predict(x_input, verbose=0).flatten()
        
        results = []
        for date, prob in zip(dates, predictions):
            results.append({
                "date": date.strftime('%Y-%m-%d %H:%M'),
                "predicted": float(prob),
                "actual": 0 
            })
            
        return results
        
    except Exception as e:
        print(f"âŒ Prediction Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/price/chart")
def get_price_history():
    try:
        df = get_binance_data(limit=1000)
        results = []
        # ìµœê·¼ 500ê°œë§Œ ë°˜í™˜ (JSON ì‘ë‹µ í¬ê¸° ì¶•ì†Œ)
        for date, row in df.tail(500).iterrows():
            results.append({
                "date": date.strftime('%Y-%m-%d %H:%M'),
                "actual": float(row['Close'])
            })
        return results
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    # ì‹¤í–‰ ì‹œ ë¡œê·¸ ë ˆë²¨ infoë¡œ ì„¤ì •
    print("ğŸš€ Server Starting...")
    uvicorn.run("GRUServer:app", host="0.0.0.0", port=8000, reload=True)
